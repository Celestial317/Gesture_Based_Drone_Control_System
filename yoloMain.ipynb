{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDQz-WkCjZn7",
        "outputId": "d72a4d9f-88e9-496c-a74d-723ec562615d"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFHUfh38jhT4",
        "outputId": "6b539f51-38ba-46f2-e3ca-709df1b9a7d7"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "\n",
        "# Load a model\n",
        "model = YOLO(\"yolo11n-pose.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrGgjaR-jqK9",
        "outputId": "126bd3a3-9641-494f-968e-c92f8ef1988d"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "results = model.train(data=\"hand-keypoints.yaml\", epochs=15, imgsz=640)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAvnCZeMkOfK",
        "outputId": "0f10ebb1-d3b0-4f4f-ce5d-4f83f43ee54b"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "cap = cv2.VideoCapture(1)\n",
        "\n",
        "if not cap.isOpened():\n",
        "    print(\"Error: Unable to access the webcam.\")\n",
        "    exit()\n",
        "\n",
        "# Main loop to process frames from the webcam\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"Error: Unable to read frame from the webcam.\")\n",
        "        break\n",
        "\n",
        "    # Resize frame for better performance\n",
        "    frame_resized = cv2.resize(frame, (640, 480))\n",
        "\n",
        "    # Perform inference\n",
        "    results = model(frame_resized)\n",
        "\n",
        "    # Extract keypoints from results\n",
        "    detections = results.xyxy[0].cpu().numpy()  # Format: [x1, y1, x2, y2, confidence, class]\n",
        "\n",
        "    # Draw keypoints on the frame\n",
        "    for det in detections:\n",
        "        x1, y1, x2, y2, conf, cls = map(int, det[:6])\n",
        "        cx, cy = (x1 + x2) // 2, (y1 + y2) // 2  # Center of the box\n",
        "        cv2.circle(frame_resized, (cx, cy), 5, (0, 255, 0), -1)  # Draw the center keypoint\n",
        "\n",
        "    # Display the frame with keypoints\n",
        "    cv2.imshow(\"Hand Keypoints Detection\", frame_resized)\n",
        "\n",
        "    # Break loop if 'q' is pressed\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release resources\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlcHeqNJewBX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
